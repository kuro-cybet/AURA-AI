# AURA-AI â€“ AI Universal Routine Advisor

AURA stands for **AI Universal Routine Advisor**.

In simple words:

> AURA is an AI that looks at your face, listens to your voice, learns your habits, and tells you the best routine for the day.

Right now, this repo is focused on **Module 1 â€“ Facial Emotion & Tiredness Detection** for a team of 4.

---

## ğŸ¯ What AURA Does (Overall Vision)

AURA combines three types of signals:

1. **Facial behaviour**  
   - Emotions: *Happy, Sad, Angry, Neutral*  
   - Tiredness: based on eyes (blinks, droopiness) and yawning  

2. **Voice behaviour** (future module)  
   - Stress level  
   - Calm vs tense tone  

3. **Daily activity patterns** (future module)  
   - Sleep time  
   - Screen time  
   - Study/work duration  
   - Break patterns  

All of this is fused to estimate your **current state** and generate a **personalised daily routine**.

Example:

> â€œYou seem tired with mild stress. Today, follow this routine:
> - 8:00â€“8:30 â€“ Light breakfast + hydration  
> - 9:00â€“11:00 â€“ High-focus task (Pomodoro 25â€“5)  
> - 12:30 â€“ Short walk (10 min)  
> - 15:00 â€“ Breathing exercise (3 minutes)  
> - Reduce phone use by 20%  
> - Sleep early, recommended 22:45â€

---

## ğŸ§± Current Focus â€“ Module 1: Face & Tiredness

We are 4 members working together **only on Module 1** right now:

- **Sudharsan** â€“ Dataset & Preprocessing  
- **Suvedhan** â€“ Model Architecture & Training  
- **Siva Dharani** â€“ Evaluation & Tiredness Rules  
- **Dhanushya** â€“ Real-Time Integration (Webcam)  

### Module 1 Objectives

- Detect **Happy / Sad / Angry / Neutral** from face images
- Detect **Tiredness** using:
  - Eye aspect ratio (EAR)
  - Blink patterns
  - Optional yawning
- Output a stable, real-time **state**:
  - `Happy/Fresh`, `Sad/Low Mood`, `Angry/Stressed`, `Neutral`, `Tired`

---

## ğŸ›ï¸ Project Structure (planned)

```bash
AURA-AI/
â”‚
â”œâ”€â”€ data/                 # Preprocessed datasets (LOCAL, usually gitignored)
â”‚   â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ val/
â”‚   â””â”€â”€ test/
â”‚
â”œâ”€â”€ models/               # Saved model weights (LOCAL, usually gitignored)
â”‚   â””â”€â”€ emotion_best.h5
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing/    # Dataset & preprocessing code
â”‚   â”œâ”€â”€ training/         # Model definitions & training scripts
â”‚   â”œâ”€â”€ evaluation/       # Metrics, confusion matrices, reports
â”‚   â””â”€â”€ realtime/         # Webcam + FaceMesh + EAR + final_state
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ ear.py            # Eye Aspect Ratio helpers
â”‚   â”œâ”€â”€ smoothing.py      # Sliding window smoothing
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ notebooks/            # Jupyter notebooks for experiments
â”‚
â”œâ”€â”€ progress/             # Daily reports (e.g. 2025-12-05.md)
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
â””â”€â”€ CONTRIBUTING.md

How to Run:(This changes in future its just for you reference now!!!!)

# 1. Clone the repo
git clone https://github.com/kuro-cybet/AURA-AI.git
cd AURA-AI

# 2. Create venv (recommended) and install requirements
pip install -r requirements.txt

# 3. (Later) Run training
python src/training/train_emotion_model.py

# 4. (Later) Run real-time detector
python src/realtime/realtime_emotion_tired.py
